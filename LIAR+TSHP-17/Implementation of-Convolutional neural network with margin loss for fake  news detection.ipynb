{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ca607e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a87f90b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Nisha\n",
      "[nltk_data]     Yadav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Nisha\n",
      "[nltk_data]     Yadav\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6e39d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, MaxPooling1D,Conv1D, GlobalMaxPooling1D,Flatten, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b771deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the LIAR dataset\n",
    "liar_data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7161b7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>robin-vos</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jim Dunnam has not lived in the district he re...</td>\n",
       "      <td>republican-party-texas</td>\n",
       "      <td>barely-true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                 speaker  \\\n",
       "0  Says the Annies List political group supports ...            dwayne-bohac   \n",
       "1  When did the decline of coal start? It started...          scott-surovell   \n",
       "2  The economic turnaround started at the end of ...           charlie-crist   \n",
       "3  The Chicago Bears have had more starting quart...               robin-vos   \n",
       "4  Jim Dunnam has not lived in the district he re...  republican-party-texas   \n",
       "\n",
       "         label  \n",
       "0        false  \n",
       "1    half-true  \n",
       "2    half-true  \n",
       "3         true  \n",
       "4  barely-true  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5bd65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stop words\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f429ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb07595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # remove punctuation and special characters\n",
    "    text = re.sub('[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove stop words\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "    # perform stemming\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "    # perform lemmatization\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2e9b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocess_text function to the 'text' column of the LIAR dataset\n",
    "liar_data['text'] = liar_data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "601ab714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    say anni list polit group support thirdtrimest...\n",
       "1    declin coal start start natur ga took start be...\n",
       "2                     econom turnaround start end term\n",
       "3    chicago bear start quarterback last 10 year to...\n",
       "4                 jim dunnam live district repres year\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar_data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a634b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the maximum number of words to consider in the vocabulary\n",
    "MAX_NB_WORDS = 50000\n",
    "\n",
    "# define the maximum length of the input sequences\n",
    "MAX_SEQUENCE_LENGTH = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30b79aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the GloVe word embeddings file\n",
    "GLOVE_PATH = 'glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95803cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tokenizer to convert words to word embeddings\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True)\n",
    "tokenizer.fit_on_texts(liar_data['text'].values)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f4effef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text data to sequences of word indices\n",
    "sequences = tokenizer.texts_to_sequences(liar_data['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "150ecdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences to ensure uniform length\n",
    "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d7f11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the GloVe word embeddings\n",
    "embeddings_index = {}\n",
    "f = open(GLOVE_PATH, encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc6a4f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in the training documents\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92f01b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(liar_data['label'])\n",
    "liar_data['label'] = encoder.transform(liar_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1c7a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train-test split\n",
    "labels = to_categorical(liar_data['label'],num_classes=6)\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c58e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (14131, 250)\n",
      "Shape of X_test: (3533, 250)\n",
      "Shape of y_train: (14131, 6)\n",
      "Shape of y_test: (3533, 6)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of the train-test split\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of X_test:', X_test.shape)\n",
    "print('Shape of y_train:', y_train.shape)\n",
    "print('Shape of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be359caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d23bcc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the fully connected layer for feature extraction\n",
    "fc_model = Sequential()\n",
    "fc_model.add(Dense(128, input_dim=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2014e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the fully connected layer for classification\n",
    "classify_model = Sequential()\n",
    "classify_model.add(Dense(6, input_dim=128, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "074840a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the margin loss function\n",
    "def margin_loss(y_true, y_pred):\n",
    "    m = 0.4\n",
    "    L = y_true * K.square(K.maximum(0., m - y_pred)) + 0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - (1 - m)))\n",
    "    return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af124c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "343009a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with margin loss function and Adam optimizer\n",
    "model = Sequential([cnn_model, fc_model, classify_model])\n",
    "model.compile(loss=margin_loss, optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "549c7bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "221/221 [==============================] - 15s 60ms/step - loss: 0.0013 - accuracy: 0.8592 - val_loss: 0.0473 - val_accuracy: 0.4931\n",
      "Epoch 2/10\n",
      "221/221 [==============================] - 14s 61ms/step - loss: 0.0013 - accuracy: 0.8646 - val_loss: 0.0464 - val_accuracy: 0.4834\n",
      "Epoch 3/10\n",
      "221/221 [==============================] - 13s 58ms/step - loss: 0.0013 - accuracy: 0.8705 - val_loss: 0.0447 - val_accuracy: 0.4880\n",
      "Epoch 4/10\n",
      "221/221 [==============================] - 13s 58ms/step - loss: 0.0013 - accuracy: 0.8664 - val_loss: 0.0458 - val_accuracy: 0.4764\n",
      "Epoch 5/10\n",
      "221/221 [==============================] - 14s 64ms/step - loss: 0.0012 - accuracy: 0.8651 - val_loss: 0.0455 - val_accuracy: 0.4928\n",
      "Epoch 6/10\n",
      "221/221 [==============================] - 13s 60ms/step - loss: 0.0010 - accuracy: 0.8779 - val_loss: 0.0455 - val_accuracy: 0.4948\n",
      "Epoch 7/10\n",
      "221/221 [==============================] - 15s 67ms/step - loss: 0.0011 - accuracy: 0.8801 - val_loss: 0.0458 - val_accuracy: 0.4979\n",
      "Epoch 8/10\n",
      "221/221 [==============================] - 14s 61ms/step - loss: 9.8449e-04 - accuracy: 0.8905 - val_loss: 0.0445 - val_accuracy: 0.4772\n",
      "Epoch 9/10\n",
      "221/221 [==============================] - 13s 58ms/step - loss: 0.0010 - accuracy: 0.8796 - val_loss: 0.0451 - val_accuracy: 0.4897\n",
      "Epoch 10/10\n",
      "221/221 [==============================] - 13s 58ms/step - loss: 0.0012 - accuracy: 0.8634 - val_loss: 0.0458 - val_accuracy: 0.4851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2db2cf8a100>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model on the train data\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b2b0b57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 18ms/step - loss: 0.0458 - accuracy: 0.4851\n",
      "Test Loss: 0.045831963419914246\n",
      "Test Accuracy: 0.4851401150226593\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a64c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
