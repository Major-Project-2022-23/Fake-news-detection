{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5a2df8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftfy\n",
    "import nltk\n",
    "import json\n",
    "import re\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "\n",
    "from collections import Counter\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, splitext, split\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9603cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dcf5ee6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>robin-vos</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jim Dunnam has not lived in the district he re...</td>\n",
       "      <td>republican-party-texas</td>\n",
       "      <td>barely-true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                 speaker  \\\n",
       "0  Says the Annies List political group supports ...            dwayne-bohac   \n",
       "1  When did the decline of coal start? It started...          scott-surovell   \n",
       "2  The economic turnaround started at the end of ...           charlie-crist   \n",
       "3  The Chicago Bears have had more starting quart...               robin-vos   \n",
       "4  Jim Dunnam has not lived in the district he re...  republican-party-texas   \n",
       "\n",
       "         label  \n",
       "0        false  \n",
       "1    half-true  \n",
       "2    half-true  \n",
       "3         true  \n",
       "4  barely-true  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3560dce",
   "metadata": {},
   "source": [
    "### Utility Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a7a8bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Regular expression for cleaning the statements\"\"\"\n",
    "\n",
    "hashtag_re = re.compile(r\"#\\w+\")\n",
    "mention_re = re.compile(r\"@\\w+\")\n",
    "url_re = re.compile(r\"(?:https?://)?(?:[-\\w]+\\.)+[a-zA-Z]{2,9}[-\\w/#~:;.?+=&%@~]*\")\n",
    "extras_re = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "#apos_re = \"\\'[a-z]*\"\n",
    "#leftover_re = \"\\S+\"\n",
    "\n",
    "\"\"\" Preprocessing the text in the statements\"\"\"\n",
    "def preprocess(text):\n",
    "    p_text = hashtag_re.sub(\"[hashtag]\",text)\n",
    "    p_text = mention_re.sub(\"[mention]\",p_text)\n",
    "    p_text = extras_re.sub(\"\",p_text)\n",
    "    p_text = url_re.sub(\"[url]\",p_text)\n",
    "    p_text = ftfy.fix_text(p_text)\n",
    "    return p_text.lower()\n",
    "\n",
    "\n",
    "# regular expression for custom tokenisation\"\n",
    "tokenise_re = re.compile(r\"(\\[[^\\]]+\\]|[-'\\w]+|[^\\s\\w\\[']+)\") #([]|words|other non-space)\n",
    "\n",
    "# defining 2 types of tokenisation\n",
    "\n",
    "def custom_tokenise(text):\n",
    "    return tokenise_re.findall(text.lower())\n",
    "\n",
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# stop words list set to english\n",
    "\n",
    "stopwords_list = stopwords.words('english') # stop word list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f2aee2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the text\n",
    "data['text']= data['text'].apply(lambda x:preprocess(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2572d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the text\n",
    "data['text']= data['text'].apply(lambda x:Tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c928225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords removal\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopWords]\n",
    "    return output\n",
    "\n",
    "data['text']= data['text'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f90237d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [say, anni, list, polit, group, support, third...\n",
       "1    [declin, coal, start, start, natur, ga, took, ...\n",
       "2               [econom, turnaround, start, end, term]\n",
       "3    [chicago, bear, start, quarterback, last, 10, ...\n",
       "4      [jim, dunnam, ha, live, district, repres, year]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d11d1b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "half-true      3673\n",
       "false          3466\n",
       "mostly-true    3320\n",
       "barely-true    2990\n",
       "true           2696\n",
       "pants-fire     1519\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e20bcbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'half-true' : 0, 'false' : 1, 'mostly-true' : 2, 'barely-true' : 3,'true': 4,'pants-fire': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9bf3083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296a81d",
   "metadata": {},
   "source": [
    "Speaker Pre-Processing -  Left-To-be-done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9e033d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Barack Obama                            563\n",
       "donald-trump                            330\n",
       "barack-obama                            253\n",
       "Mitt Romney                             205\n",
       "hillary-clinton                         201\n",
       "                                       ... \n",
       "gen-peter-chiarelli                       1\n",
       "jeff-mullis                               1\n",
       "association-mature-american-citizens      1\n",
       "john-albers                               1\n",
       "Jason Chaffetz                            1\n",
       "Name: speaker, Length: 5105, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['speaker'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a588012b",
   "metadata": {},
   "source": [
    "#### Splitting the datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1a7bf070",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(data, target = 'label', \n",
    "                                                                            train_size=0.8, valid_size=0.1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "99552e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2966\n",
      "1    2768\n",
      "2    2679\n",
      "3    2367\n",
      "4    2111\n",
      "5    1240\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f4356712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    364\n",
      "1    346\n",
      "3    310\n",
      "2    307\n",
      "4    294\n",
      "5    145\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_valid.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "10f2ac5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    352\n",
      "0    343\n",
      "2    334\n",
      "3    313\n",
      "4    291\n",
      "5    134\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b18b447b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(lowercase=False, max_features=1000, ngram_range=(1, 3),\n",
       "                stop_words='english',\n",
       "                tokenizer=<function identity_tokenizer at 0x0000025322F38040>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "cv = CountVectorizer(tokenizer=identity_tokenizer,stop_words='english', lowercase=False,max_features=1000,ngram_range=(1,3))\n",
    "cv.fit(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6889e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer_train_vectors = cv.fit_transform(X_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9707958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14131x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 118804 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer_train_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "176a88b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer_valid_vectors = cv.fit_transform(X_valid['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4a790620",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer_test_vectors = cv.fit_transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf6fbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d725c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53465623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e77d59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66926d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6947d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bcb634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2335661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b37e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af2537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d0159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2470c7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18f7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e126216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
