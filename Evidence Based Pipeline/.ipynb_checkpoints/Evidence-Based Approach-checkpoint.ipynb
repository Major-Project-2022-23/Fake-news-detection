{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import texthero as hero\n",
    "from urllib.parse import urlsplit\n",
    "import requests\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "from huggingface_hub import from_pretrained_keras\n",
    "import spacy_sentence_bert\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import Summarizer,TransformerSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO\n",
    "1. News section search - Done\n",
    "2. Abstarctive summary\n",
    "3. Specify cap on number of links\n",
    "4. Search Keywords\n",
    "5. Tune similarity parameter n Model\n",
    "6. Use summary or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from GoogleNews import GoogleNews\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenews = GoogleNews(start='12/31/2019',end='01/01/2023', lang='en')\n",
    "googlenews.set_encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_from_google_news(claim, top=10):\n",
    "    googlenews.search(claim)\n",
    "    \n",
    "    results = googlenews.results()\n",
    "    googlenews.clear()\n",
    "    \n",
    "#     results = [x for x in results if isinstance(x['datetime'], datetime)]\n",
    "    \n",
    "#     def func(ele):\n",
    "#         return str(ele['datetime'])\n",
    "    \n",
    "#     results.sort(key = func, reverse = True)\n",
    "    links = [x['link'] for x in results]\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy_sentence_bert.load_model('en_nli_roberta_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_from_link(link, text, top=10):\n",
    "    request = requests.get(link, verify=False, timeout=20)\n",
    "    Soup = BeautifulSoup(request.text, 'lxml')\n",
    "    \n",
    "    heading_tags = ['p']\n",
    "\n",
    "\n",
    "    results = []\n",
    "    used = []\n",
    "\n",
    "    for tags in Soup.find_all(heading_tags):\n",
    "        if 'h' in tags.name:\n",
    "            tokens = tags.text.strip().split()\n",
    "            if len(tokens) > 8:\n",
    "                if tags.text.strip() not in used:\n",
    "                    used.append(tags.text.strip())\n",
    "                    results.append([tags.name, tags.text.strip()])\n",
    "        else:\n",
    "            tokens = tags.text.strip().split()\n",
    "            if len(tokens) > 8:\n",
    "                if tags.text.strip() not in used:\n",
    "                    used.append(tags.text.strip())\n",
    "                    results.append([tags.name, tags.text.strip()])\n",
    "    doc1 = nlp(text)\n",
    "    sim = []\n",
    "    for r in results:\n",
    "        sim.append(doc1.similarity(nlp(r[1])))\n",
    "    zipped = zip(sim, results)\n",
    "    zipped = sorted(zipped, reverse=True)\n",
    "    high_conf = [a for s, a in zipped if s >= 0.6]\n",
    "\n",
    "    return high_conf[:top], request.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_evidences(text, links):\n",
    "    new_links = []\n",
    "    for link in links:\n",
    "        conf, lin = get_sentences_from_link(link, text)\n",
    "        new_links.append([lin, conf])\n",
    "    return new_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatinating Evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_evidences(claim, links):\n",
    "    summ = []\n",
    "    for link in links:\n",
    "        if type(link[1]) == list:\n",
    "            for text in link[1]:\n",
    "                if type(link[1]) == list:\n",
    "                    summ.append(text[1])\n",
    "                else:\n",
    "                    summ.append(text)\n",
    "        elif type(link[1]) == str:\n",
    "            summ.append(link[1])\n",
    "\n",
    "    urls = re.findall(r'https?:\\/+\\/+t+\\.+co+\\/+\\S*', claim)\n",
    "    \n",
    "    for li in urls:\n",
    "        claim = claim.replace(li, '')\n",
    "    claim = claim.strip()\n",
    "\n",
    "    if summ:\n",
    "        summary = (claim, ' '.join(summ).replace('\\n', '').replace('\\t', ''))\n",
    "    else:\n",
    "        summary = ('', '')\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = Summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_extractive_summary(evidence):\n",
    "    return ''.join(summarizer(evidence, min_length=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstractive_summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstractive_summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_abstractive_summary(evidence):\n",
    "    return abstractive_summarizer(evidence, min_length=5, do_sample=False)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Based Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"Generates batches of data.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentence_pairs,\n",
    "        labels,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        include_targets=True,\n",
    "    ):\n",
    "        self.sentence_pairs = sentence_pairs\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.include_targets = include_targets\n",
    "        # Load our BERT Tokenizer to encode the text.\n",
    "        # We will use base-base-uncased pretrained model.\n",
    "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n",
    "            \"bert-base-uncased\", do_lower_case=True\n",
    "        )\n",
    "        self.indexes = np.arange(len(self.sentence_pairs))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch.\n",
    "        return len(self.sentence_pairs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieves the batch of index.\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        sentence_pairs = self.sentence_pairs[indexes]\n",
    "\n",
    "        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n",
    "        # encoded together and separated by [SEP] token.\n",
    "        encoded = self.tokenizer.batch_encode_plus(\n",
    "            sentence_pairs.tolist(),\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            pad_to_max_length=True,\n",
    "            return_tensors=\"tf\",\n",
    "        )\n",
    "\n",
    "        # Convert batch of encoded features to numpy array.\n",
    "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
    "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
    "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
    "\n",
    "        # Set to true if data generator is used for training/validation.\n",
    "        if self.include_targets:\n",
    "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
    "            return [input_ids, attention_masks, token_type_ids], labels\n",
    "        else:\n",
    "            return [input_ids, attention_masks, token_type_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in HuggingFace Hub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = from_pretrained_keras(\"keras-io/bert-semantic-similarity\")\n",
    "labels = [\"contradiction\", \"entailment\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence1, sentence2):\n",
    "    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
    "    test_data = BertSemanticDataGenerator(\n",
    "        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
    "    )\n",
    "    probs = model.predict(test_data[0])[0]\n",
    "    \n",
    "    labels_probs = {labels[i]: float(probs[i]) for i, _ in enumerate(labels)}\n",
    "    return labels_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake News Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_news_detection(claim):\n",
    "#     start = timer()\n",
    "    links = get_links_from_google_news(claim)\n",
    "#     print(\"links ----- \")\n",
    "#     print(links)\n",
    "    evidence_list = scrap_evidences(claim, links[:10])\n",
    "#     print(\"Evidence List ----- \")\n",
    "#     print(evidence_list)\n",
    "    evidence = concatenate_evidences(claim, evidence_list)\n",
    "#     print(\"Concatenated Evidence ----- \")\n",
    "#     print(evidence[1])\n",
    "#     print(\"Results with Concatenated Evidence\")\n",
    "    k = predict(claim, evidence[1])\n",
    "    print(k)\n",
    "#     extractive_summary = generate_extractive_summary(evidence[1])\n",
    "#     print(\"Extractive Summary ----- \")\n",
    "#     print(extractive_summary)\n",
    "#     print(\"Results with Extractive Summary\")\n",
    "#     print(predict(claim, extractive_summary))\n",
    "#     abstractive_summary = generate_abstractive_summary(evidence[1])\n",
    "#     print(\"Abstractive Summary ----- \")\n",
    "#     print(abstractive_summary)\n",
    "#     print(\"Results with Abstractive Summary\")\n",
    "#     print(predict(claim, abstractive_summary))\n",
    "#     end = timer()\n",
    "#     print(end - start)\n",
    "#     return evidence[1]\n",
    "    return (k,  evidence[1])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 282ms/step\n",
      "{'contradiction': 0.9914847016334534, 'entailment': 3.280447344877757e-05, 'neutral': 0.00848244596272707}\n"
     ]
    }
   ],
   "source": [
    "# claim = \"Times Of India Shares Fake Cropped Bungee Jump Fail Video\"\n",
    "# # claim = \"People from LGBTQ Community can marry in india\"\n",
    "# v = fake_news_detection(claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'contradiction': 0.9914847016334534, 'entailment': 3.280447344877757e-05, 'neutral': 0.00848244596272707}, \"Erin Langworthy witnessed the latter in a situation which may sound like a scripted scene from a film. Not only did her bungee cord snap and she was sent 360 ft down in a water body. But the water body where Erin fell, was later discovered to be infested with crocodile. A native of Australia, Erin had been on a holiday to Africa, when she decided to bungee jump off a bridge in Zambia’s Zambezi River. While the incident transpired way back in 2012, it was only recently that the video of the incident garnered the attention of netizens. Erin reportedly took a trip to Victoria Falls where she decided to bungee jump above the Zambezi river. A woman recently fell 360 ft in a bungee jumping mishap as the bungee cord snap. Miraculously, the woman survived to tell the tale and mentioned how she joked about dying a day before the mishap. The woman in question was identified as Erin Langworthy. Erin’s bungee jumping ordeal was more adventurous than she would’ve hoped for, after the bungee cord snapped, throwing her in a water body filled with crocodiles! For a while, everything transpired how it is supposed to. Diving from the platform, Erin felt the cool air on her face. However, before she could enjoy the remaining part of the bungee jump, she realized that the cord had snapped. Gravity did its thing and Erin was sent straight into a river infested with crocodiles. Erin’s hair-raising tryst with bungee jumping was caught on a camera, video of which, has been making rounds of social media since the incident happened (2012). Video of her bungee jumping going wrong shows her smoothly diving into the abyss of the river. However, instead of bouncing back as a person bungee jumping is supposed to, Erin kept floating and fell 360 ft into the river. Also Read: Woman Falls 360ft in Bungee Jumping Mishap as Cord Snaps, Lives to Tell the Tale of Joking About Death| Video Swarna Prabhat, the Superintendent of Police, Bhagalpur, was quoted in an NDTV report saying, “On Saturday, the woman was killed by a sharp weapon attack near the Scindia bridge. Before the people could understand anything, the attackers ran away, waving their weapons”. Also Read: Woman Falls 360ft in Bungee Jumping Mishap as Cord Snaps, Lives to Tell the Tale of Joking About Death | Video Joshua Hammer is the author of ‘The Falcon Thief: A True Tale of Adventure, Treachery, and the Hunt for the Perfect Bird.’ The eruption of White Island on December 9 was a shock but not a surprise. The volcano had been stirring with intention for thousands of years. It's been easy for visitors to downplay the dangers. Or misjudge them altogether. When Captain James Cook sailed by the island in 1769, he gave the rocky crater the name White Island because he mistook the puffs of volcanic steam for cloud formations. The indigenous Maori, on the other hand, gave it a more apt moniker. They called the place Te Puia O Whakaari, “the dramatic volcano,” and believed that spirits had summoned the gift of fire from deep beneath the island, granting it to their ancestors. At the moment of the blast, the difference between who lived and who died largely came down to happenstance. Could they find shelter of some kind—a boulder, a gully, a sulfur pillar—when the cloud passed over them? Two foreign tourists who had arrived on the helicopter that now lay mangled by the water's edge were standing on the shore when the pyroclastic surge swept toward them. Stories about what happened next later reached the Cessna pilot George Walker. “They were going, ‘Fuck, fuck, fuck,’ ” he said. “Their pilot told them to jump into the sea. They had no injuries whatsoever.” Two fellow passengers, who failed to move as quickly, were horribly burned. Nobody on the island managed to take refuge inside the shipping container—White Island Tours' last-ditch safety measure. After the eruption, Nico Fournier had told me, the water had depressurized and drained almost completely, but now the basin had refilled. “We're going to see the remains of the helicopter now,” Walker said, passing low over the crater so I could glimpse the wrecked aircraft, which rested near an abandoned fertilizer factory, two of its three rotor blades blown off. “The eruption pushed 800 kilograms 800 meters,” Walker said. “It was essentially a bomb going off.” I caught a whiff of sulfur, and the pilot banked, exposing the green-yellow volcanic plain, crisscrossed by hiking trails. I had a clear view of the path that the gas-and-steam cloud had followed, enveloping more than 40 unsuspecting people in fire and darkness.\")\n"
     ]
    }
   ],
   "source": [
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_abstractive_summary(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('IFND_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac = 1)\n",
    "data = data.reset_index()\n",
    "data = data.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Web</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>Pranab Mukherjee remains haemodynamically stab...</td>\n",
       "      <td>INDIANEXPRESS</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259</td>\n",
       "      <td>How long will we have to wait for UN reforms, ...</td>\n",
       "      <td>TRIBUNEINDIA</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670</td>\n",
       "      <td>Unrelated Notification viral as proposal to re...</td>\n",
       "      <td>FACTCRESCENDO</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2022-10-19</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>214</td>\n",
       "      <td>Central Trade Unions will up the ante in view ...</td>\n",
       "      <td>TRIBUNEINDIA</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>630</td>\n",
       "      <td>Have the Rohingya Muslims inhabited the empty ...</td>\n",
       "      <td>FACTCRESCENDO</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>2022-06-19</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          Statement            Web  \\\n",
       "0   65  Pranab Mukherjee remains haemodynamically stab...  INDIANEXPRESS   \n",
       "1  259  How long will we have to wait for UN reforms, ...   TRIBUNEINDIA   \n",
       "2  670  Unrelated Notification viral as proposal to re...  FACTCRESCENDO   \n",
       "3  214  Central Trade Unions will up the ante in view ...   TRIBUNEINDIA   \n",
       "4  630  Have the Rohingya Muslims inhabited the empty ...  FACTCRESCENDO   \n",
       "\n",
       "   Category       Date Label  \n",
       "0  POLITICS 2020-08-01  True  \n",
       "1  POLITICS 2020-09-01  True  \n",
       "2  POLITICS 2022-10-19  Fake  \n",
       "3  POLITICS 2020-10-01  True  \n",
       "4  POLITICS 2022-06-19  Fake  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VERY SENSITIVE PIECE OF CODE\n",
    "# with open(filename, 'w') as csvfile:\n",
    "#     csvwriter = csv.writer(csvfile)\n",
    "#     csvwriter.writerow(['id', 'contradiction', 'entailment', 'neutral', 'evidence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n",
      "failed at 501\n",
      "502\n",
      "failed at 502\n",
      "503\n",
      "failed at 503\n",
      "504\n",
      "failed at 504\n",
      "505\n",
      "failed at 505\n",
      "506\n",
      "failed at 506\n",
      "507\n",
      "failed at 507\n",
      "508\n",
      "failed at 508\n",
      "509\n",
      "failed at 509\n",
      "510\n",
      "failed at 510\n",
      "511\n",
      "failed at 511\n",
      "512\n",
      "failed at 512\n",
      "513\n",
      "failed at 513\n",
      "514\n",
      "failed at 514\n",
      "515\n",
      "failed at 515\n",
      "516\n",
      "failed at 516\n",
      "517\n",
      "failed at 517\n",
      "518\n",
      "failed at 518\n",
      "519\n",
      "failed at 519\n",
      "520\n",
      "failed at 520\n",
      "521\n",
      "failed at 521\n",
      "522\n",
      "failed at 522\n",
      "523\n",
      "failed at 523\n",
      "524\n",
      "failed at 524\n",
      "525\n",
      "failed at 525\n",
      "526\n",
      "failed at 526\n",
      "527\n",
      "failed at 527\n",
      "528\n",
      "failed at 528\n",
      "529\n",
      "failed at 529\n",
      "530\n",
      "failed at 530\n",
      "531\n",
      "failed at 531\n",
      "532\n",
      "failed at 532\n",
      "533\n",
      "failed at 533\n",
      "534\n",
      "failed at 534\n",
      "535\n",
      "failed at 535\n",
      "536\n",
      "failed at 536\n",
      "537\n",
      "failed at 537\n",
      "538\n",
      "failed at 538\n",
      "539\n",
      "failed at 539\n",
      "540\n",
      "failed at 540\n",
      "541\n",
      "failed at 541\n",
      "542\n",
      "failed at 542\n",
      "543\n",
      "failed at 543\n",
      "544\n",
      "failed at 544\n",
      "545\n",
      "failed at 545\n",
      "546\n",
      "failed at 546\n",
      "547\n",
      "failed at 547\n",
      "548\n",
      "failed at 548\n",
      "549\n",
      "failed at 549\n",
      "550\n",
      "failed at 550\n",
      "551\n",
      "failed at 551\n",
      "552\n",
      "failed at 552\n",
      "553\n",
      "failed at 553\n",
      "554\n",
      "failed at 554\n",
      "555\n",
      "failed at 555\n",
      "556\n",
      "failed at 556\n",
      "557\n",
      "failed at 557\n",
      "558\n",
      "failed at 558\n",
      "559\n",
      "failed at 559\n",
      "560\n",
      "failed at 560\n",
      "561\n",
      "failed at 561\n",
      "562\n",
      "failed at 562\n",
      "563\n",
      "failed at 563\n",
      "564\n",
      "failed at 564\n",
      "565\n",
      "failed at 565\n",
      "566\n",
      "failed at 566\n",
      "567\n",
      "failed at 567\n",
      "568\n",
      "failed at 568\n",
      "569\n",
      "failed at 569\n",
      "570\n",
      "failed at 570\n",
      "571\n",
      "failed at 571\n",
      "572\n",
      "failed at 572\n",
      "573\n",
      "failed at 573\n",
      "574\n",
      "failed at 574\n",
      "575\n",
      "failed at 575\n",
      "576\n",
      "failed at 576\n",
      "577\n",
      "failed at 577\n",
      "578\n",
      "failed at 578\n",
      "579\n",
      "failed at 579\n",
      "580\n",
      "failed at 580\n",
      "581\n",
      "failed at 581\n",
      "582\n",
      "failed at 582\n",
      "583\n",
      "failed at 583\n",
      "584\n",
      "failed at 584\n",
      "585\n",
      "failed at 585\n",
      "586\n",
      "failed at 586\n",
      "587\n",
      "failed at 587\n",
      "588\n",
      "failed at 588\n",
      "589\n",
      "failed at 589\n",
      "590\n",
      "failed at 590\n",
      "591\n",
      "failed at 591\n",
      "592\n",
      "failed at 592\n",
      "593\n",
      "failed at 593\n",
      "594\n",
      "failed at 594\n",
      "595\n",
      "failed at 595\n",
      "596\n",
      "failed at 596\n",
      "597\n",
      "failed at 597\n",
      "598\n",
      "'NoneType' object is not iterable\n",
      "failed at 598\n",
      "599\n",
      "failed at 599\n"
     ]
    }
   ],
   "source": [
    "with open(filename, 'a') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    for i in range(600, 700):\n",
    "        print(i)\n",
    "        try:\n",
    "            v = fake_news_detection(data.iloc[i]['Statement'])\n",
    "            csvwriter.writerow([data.iloc[i]['id'], v[0]['contradiction'], v[0]['entailment'], v[0]['neutral'], v[1]])\n",
    "        except:\n",
    "            print(\"failed at \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>contradiction</th>\n",
       "      <th>entailment</th>\n",
       "      <th>neutral</th>\n",
       "      <th>evidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.991485</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.991485</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  contradiction  entailment   neutral evidence\n",
       "0   0       0.991485    0.000033  0.008482      ABC\n",
       "1   0       0.991485    0.000033  0.008482      ABC"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
